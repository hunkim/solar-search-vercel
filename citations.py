import requests
import json
import re
import os
from collections import OrderedDict
from datetime import datetime


class CitationManager:
    """Handles citation processing and search query extraction for Solar API responses."""
    
    def __init__(self, solar_api):
        """Initialize with reference to Solar API instance."""
        self.solar_api = solar_api
    
    def add_citations(self, response_text, sources):
        """
        Adds citations to response text based on sources, only including relevant citation numbers.
        
        Args:
            response_text (str): The response text with citation numbers like [1], [2]
            sources (list): A list of source dictionaries
            
        Returns:
            dict: A dictionary with cited_text and filtered references
        """
        try:
            # First check if response_text already contains citations
            citation_pattern = r'\[(\d+(?:,\s*\d+)*)\]'
            found_citations = set()
            for match in re.findall(citation_pattern, response_text):
                # Handle both single numbers and comma-separated numbers
                for num in re.split(r',\s*', match):
                    found_citations.add(int(num))
            
            # If no citations found, return original text with empty references
            if not found_citations:
                return json.dumps({"cited_text": response_text, "references": []})
            
            # Filter sources to only include those referenced in text
            filtered_references = []
            for source in sources:
                # Get the source ID/number
                source_num = source.get('id', None)
                if source_num is not None and source_num in found_citations:
                    filtered_references.append({
                        "number": source_num,
                        "url": source.get("url", ""),
                        "title": source.get("title", "")
                    })
            
            return json.dumps({
                "cited_text": response_text,
                "references": filtered_references
            })
        except Exception as e:
            print(f"Error in add_citations: {e}")
            return json.dumps({"cited_text": response_text, "references": []})
    
    def fill_citation_heuristic(self, response_text, sources):
        """
        Adds citations to response_text based on keyword overlap heuristic.

        Args:
            response_text: The text generated by the LLM.
            sources: A list of source dictionaries, each potentially containing
                     'url', 'title', 'content'.

        Returns:
            A JSON string with 'cited_text' and 'references', or None if error.
        """
        if not response_text or not sources:
            # Return original text if no sources or text to cite
            return json.dumps({"cited_text": response_text or "", "references": []})

        # Simple English stop words list (can be expanded)
        stop_words = set([
            "i", "me", "my", "myself", "we", "our", "ours", "ourselves", "you", "your", "yours",
            "yourself", "yourselves", "he", "him", "his", "himself", "she", "her", "hers",
            "herself", "it", "its", "itself", "they", "them", "their", "theirs", "themselves",
            "what", "which", "who", "whom", "this", "that", "these", "those", "am", "is", "are",
            "was", "were", "be", "been", "being", "have", "has", "had", "having", "do", "does",
            "did", "doing", "a", "an", "the", "and", "but", "if", "or", "because", "as", "until",
            "while", "of", "at", "by", "for", "with", "about", "against", "between", "into",
            "through", "during", "before", "after", "above", "below", "to", "from", "up", "down",
            "in", "out", "on", "off", "over", "under", "again", "further", "then", "once", "here",
            "there", "when", "where", "why", "how", "all", "any", "both", "each", "few", "more",
            "most", "other", "some", "such", "no", "nor", "not", "only", "own", "same", "so",
            "than", "too", "very", "s", "t", "can", "will", "just", "don", "should", "now"
        ])

        def get_words(text):
            """Basic tokenizer and stop word removal."""
            if not text: return set()
            words = re.findall(r'\b\w+\b', text.lower())
            return set(word for word in words if word not in stop_words and len(word) > 1)

        # --- Dynamic Threshold Setup ---
        initial_threshold = 4  # Start with the desired "high relevance" threshold
        min_threshold = 2      # Minimum acceptable overlap to avoid excessive noise (adjust if needed)
        current_threshold = initial_threshold
        # -----------------------------

        # Prepare sources with numbers and pre-process content
        numbered_sources = []
        source_details_map = {} # Map original number to details for later lookup
        for i, source in enumerate(sources):
            content_words = get_words(source.get('content'))
            original_num = i + 1
            if content_words: # Only consider sources with processable content
                details = {
                    "number": original_num,
                    "url": source.get("url", ""),
                    "title": source.get("title", ""), # Keep title
                    "content_words": content_words
                }
                numbered_sources.append(details)
                source_details_map[original_num] = details

        if not numbered_sources:
             return json.dumps({"cited_text": response_text, "references": []})

        # Split text into sentences
        sentences = re.split(r'(?<=[.!?])\s+', response_text)

        # --- Loop for Dynamic Threshold ---
        final_sentences_with_citations = [] # Store results from the successful pass
        
        while current_threshold >= min_threshold:
            print(f"Attempting citation with threshold: {current_threshold}") # Logging/Debug
            
            # Reset results for this specific threshold attempt
            current_pass_sentences = []
            any_citations_found_this_pass = False

            for sentence in sentences:
                if not sentence.strip():
                    continue

                sentence_words = get_words(sentence)
                # Add sentence structure even if no words or no citations found later
                sentence_entry = {"text": sentence, "citations": []}

                if not sentence_words:
                     current_pass_sentences.append(sentence_entry)
                     continue

                matching_source_nums = []
                for source in numbered_sources:
                    overlap = sentence_words.intersection(source["content_words"])
                    # Use the *current* threshold for checking
                    if len(overlap) >= current_threshold:
                        matching_source_nums.append(source["number"])
                        any_citations_found_this_pass = True # Mark success for this pass

                # Sort original numbers for consistent intermediate representation
                matching_source_nums.sort()
                sentence_entry["citations"] = matching_source_nums
                current_pass_sentences.append(sentence_entry)

            # Check if citations were found in this pass
            if any_citations_found_this_pass:
                print(f"Found citations at threshold {current_threshold}. Using these results.") # Logging/Debug
                final_sentences_with_citations = current_pass_sentences # Store the successful results
                break # Exit the while loop, we found citations
            else:
                print(f"No citations found at threshold {current_threshold}. Decreasing threshold.") # Logging/Debug
                current_threshold -= 1
                # Continue to the next iteration of the while loop with lower threshold

        # Handle case where loop finished without finding any citations
        if not final_sentences_with_citations:
             print(f"No citations found even at minimum threshold {min_threshold}. Proceeding without citations.") # Logging/Debug
             # Populate with original sentences and empty citations if loop failed
             final_sentences_with_citations = [{"text": s, "citations": []} for s in sentences if s.strip()]
        # --- End Dynamic Threshold Loop ---

        # --- Reordering Logic (Uses final_sentences_with_citations) ---
        # This part remains largely the same, but uses the list determined by the dynamic threshold loop
        final_cited_sentences = []
        old_to_new_mapping = OrderedDict()
        next_new_citation_num = 1

        # First pass: Find unique citations in order of appearance
        for sentence_data in final_sentences_with_citations: # Use the final list
            for original_num in sentence_data["citations"]:
                if original_num not in old_to_new_mapping:
                    old_to_new_mapping[original_num] = next_new_citation_num
                    next_new_citation_num += 1

        # Second pass: Replace original numbers with new sequential numbers
        for sentence_data in final_sentences_with_citations: # Use the final list
            original_sentence_text = sentence_data["text"]
            # Use .get() default to handle potential empty list if no citations found at all
            new_citation_nums = [old_to_new_mapping.get(orig_num) for orig_num in sentence_data["citations"]]
            # Filter out None values in case of unexpected issue, though should not happen with current logic
            new_citation_nums = [num for num in new_citation_nums if num is not None]


            if new_citation_nums:
                # Sort the *new* numbers for consistent display
                new_citation_nums.sort()
                # Add space before the first citation only, then no spaces between consecutive citations
                citation_str = f" [" + "][".join([str(num) for num in new_citation_nums]) + "]"

                # Insert citation before trailing punctuation
                sentence_strip = original_sentence_text.rstrip()
                trailing_punctuation = ""
                if sentence_strip and sentence_strip[-1] in '.!?':
                    trailing_punctuation = sentence_strip[-1]
                    sentence_base = sentence_strip[:-1].rstrip()
                else:
                    sentence_base = sentence_strip

                cited_sentence = sentence_base + citation_str + trailing_punctuation
                final_cited_sentences.append(cited_sentence)
            else:
                # Append original sentence if no citation needed
                final_cited_sentences.append(original_sentence_text)
        # --- End Reordering Logic ---

        # Reconstruct the final text
        cited_text = " ".join(final_cited_sentences)

        # Build references list using the new mapping
        references = []
        # Iterate through the mapping in the order citations were encountered
        for original_num, new_num in old_to_new_mapping.items():
            # Retrieve original source details using the original number
            source_details = source_details_map.get(original_num)
            if source_details:
                 references.append({
                    "number": new_num, # Use the new sequential number
                    "url": source_details["url"],
                    "title": source_details["title"]
                })
            else:
                 # Should not happen if logic is correct, but handle defensively
                 print(f"Warning: Could not find details for original source number {original_num}")


        # Ensure references are sorted by the new number (already implicitly sorted by OrderedDict iteration)
        # references.sort(key=lambda x: x["number"]) # Technically redundant with OrderedDict

        # Return JSON structure
        result = {
            "cited_text": cited_text,
            "references": references
        }
        try:
            return json.dumps(result, indent=2) # Pretty print JSON
        except Exception as e:
            print(f"Error serializing citation result to JSON: {e}")
            return json.dumps({"cited_text": response_text, "references": []}) # Fallback

    def fill_citation(self, response_text, sources, model="solar-pro-nightly"):
        """Generate citations for response text using LLM to intelligently place citations."""
        prompt = f"""Add citation numbers to the response text where information comes from the provided sources.
---
RESPONSE TEXT:
{response_text}
---
SOURCES:
{json.dumps(sources, indent=2)}
---
INSTRUCTIONS:
1. Read the response text and sources carefully.
2. Add citation numbers [1], [2], etc. directly after the specific word or sentence that uses information from the sources. Add citations only for highly relevant information derived from the sources.
3. Only add citation numbers - don't change the original text otherwise.
4. Add 3 to 5 important citations at most.
5. IMPORTANT: Copy URLs EXACTLY as they appear in the sources - URLs must be precise and complete.
6. Return a JSON object with this structure:
   {{
     "cited_text": "text with added citation numbers[1], [2], etc.",
     "references": [
       {{
         "number": 1,
         "url": "https://example.com/source1"
       }}
     ]
   }}

EXAMPLE:

Response: "The iPhone 15 Pro features a titanium frame and a 48-megapixel camera."

Sources: [
  {{"id": 1, "title": "iPhone 15 Pro Review", "url": "https://example.com/review1", "content": "Apple's iPhone 15 Pro features a titanium frame, making it lighter than previous models."}},
  {{"id": 3, "title": "Camera Comparison", "url": "https://example.com/cameras", "content": "With its 48-megapixel main camera, the iPhone 15 Pro captures remarkable detail."}}
]

Output:
{{
  "cited_text": "The iPhone 15 Pro features a titanium frame[1] and a 48-megapixel camera.[2]",
  "references": [
    {{
      "number": 1,
      "url": "https://example.com/review1"
    }},
    {{
      "number": 2,
      "url": "https://example.com/cameras"
    }}
  ]
}}

CRITICAL: 
- Take special care to copy each URL EXACTLY as provided in the sources - do not modify, truncate, or reformat URLs
- Check each URL carefully before including it in the references
- URLs must be complete and functional to ensure proper citation links

Only add citations when there's a clear match between the text and sources. Return valid JSON.
"""

        citation_added_response = self.solar_api.complete(
            prompt=prompt,
            model=model,
            stream=False
        )
        return citation_added_response


def extract_search_queries(user_prompt, solar_api, max_attempts=3, model="solar-pro-nightly"):
    """
    Extract 2-3 optimal search queries from a user prompt to maximize search engine relevance.
    
    Args:
        user_prompt (str): The user's input prompt/question
        solar_api: SolarAPI instance to use for completion
        max_attempts (int): Maximum number of attempts to get valid JSON response
        model (str): Model to use for completion
        
    Returns:
        str: JSON formatted string containing 2-3 search queries
    """
    prompt = f"""
    Given the following user question or request, generate 2-3 different search queries that would help retrieve the most relevant information from a search engine.

    IMPORTANT RULES:
    1. If the request involves a comparison (e.g., "A vs B" or "differences between X and Y"), create separate queries for each component individually (e.g., one query about A, one query about B)
    2. For multi-part questions, divide your queries to address each component separately
    3. Break down complex topics into their fundamental elements
    
    Your search queries should:
    - Extract key concepts and technical terms
    - Remove filler words and focus on essential keywords
    - Be concise and directly relevant to the information need
    - Include specific technical terminology where appropriate
    
    User request: "{user_prompt}"
    
    Examples:
    - User: "How do I implement a binary search tree in Python?"
      Queries: ["python binary search tree implementation", "BST data structure python code", "binary tree algorithms python"]
    
    - User: "What are the advantages of React over Angular for building web applications?"
      Queries: ["React framework features benefits", "Angular framework capabilities", "React vs Angular performance"]
    
    - User: "Explain the difference between supervised and unsupervised machine learning"
      Queries: ["supervised learning algorithms principles", "unsupervised learning methods examples", "machine learning types comparison"]
      
    - User: "Compare AWS Lambda and Google Cloud Functions for serverless applications"
      Queries: ["AWS Lambda serverless features", "Google Cloud Functions capabilities", "serverless platform comparison criteria"]
    
    Return ONLY a JSON object with this format:
    {{"search_queries": ["query1", "query2", "query3"]}}
    """
    
    # Make multiple attempts to get valid JSON
    response = ""
    for attempt in range(max_attempts):
        try:
            # Get completion from Solar API
            response = solar_api.complete(prompt, model=model, stream=False)
            
            # Try to parse as JSON
            queries = json.loads(response)
            
            # Validate the structure - make sure it has search_queries field
            if "search_queries" not in queries:
                queries = {"search_queries": list(queries.values())[0] if queries else [user_prompt]}
            
            # Ensure we have at most 3 queries
            queries["search_queries"] = queries["search_queries"][:3]
            
            # Return properly formatted JSON
            return json.dumps(queries, indent=2)
            
        except (json.JSONDecodeError, KeyError, IndexError):
            # If this is the last attempt, we'll fall through to the backup method
            if attempt == max_attempts - 1:
                break
            
            # Otherwise, modify the prompt to emphasize JSON formatting
            prompt += "\n\nIMPORTANT: Return ONLY a valid JSON object with the format {\"search_queries\": [\"query1\", \"query2\", \"query3\"]}. No other text."
        except Exception:
            # Handle any API errors by falling through to backup method
            response = ""
            break
    
    # Backup method: extract potential queries using regex
    
    # Look for quoted strings that might be our queries
    queries = re.findall(r'"([^"]*)"', response)
    
    # If we couldn't find any quoted strings, try looking for text between brackets
    if not queries:
        bracket_content = re.search(r'\[(.*?)\]', response)
        if bracket_content:
            queries = [q.strip().strip('"\'') for q in bracket_content.group(1).split(',')]
    
    # If all extraction methods failed, use the original prompt as a single query
    if not queries:
        queries = [user_prompt]
    
    # Ensure we have 2-3 queries (take up to 3)
    queries = queries[:3]
    
    # If we have fewer than 2 queries, add variations of the first query
    while len(queries) < 2 and queries:
        queries.append(f"alternative {queries[0]}")
    
    return json.dumps({"search_queries": queries}, indent=2) 